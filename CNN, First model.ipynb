{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, First model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 199483 training samples, 49871 test samples\n",
      "The length of each review is 100.\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "with open('X_train_even.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "    \n",
    "with open('Y_train_even.pickle', 'rb') as handle:\n",
    "    Y_train = pickle.load(handle)\n",
    "    \n",
    "with open('scores_train_even.pickle', 'rb') as handle:\n",
    "    scores_train = pickle.load(handle)\n",
    "    \n",
    "with open('X_test_even.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "    \n",
    "with open('Y_test_even.pickle', 'rb') as handle:\n",
    "    Y_test = pickle.load(handle)\n",
    "    \n",
    "with open('scores_test_even.pickle', 'rb') as handle:\n",
    "    scores_test = pickle.load(handle)\n",
    "    \n",
    "# import dictionaries\n",
    "with open('ix_to_word.pickle', 'rb') as handle:\n",
    "    ix_to_word = pickle.load(handle)\n",
    "    \n",
    "# small change in format\n",
    "tmp = np.concatenate(X_train).ravel()\n",
    "X_train = np.reshape(tmp,(len(X_train),100))\n",
    "\n",
    "tmp = np.concatenate(X_test).ravel()\n",
    "X_test = np.reshape(tmp,(len(X_test),100))\n",
    "\n",
    "review_length = X_test.shape[1]\n",
    "num_words = 46210\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print('The length of each review is {}.'.format(review_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 10000\n",
    "\n",
    "small_Y = Y_train[0:num_datapoints]\n",
    "small_X = X_train[0:num_datapoints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_conv_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_regularized_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_regularized_larger_kernel_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_regularized_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=30, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=20, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_more_filter_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_larger_kernel_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=5, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_nn(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 16s 99us/step - loss: 0.3315 - acc: 0.8544 - val_loss: 0.2614 - val_acc: 0.8952\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.1892 - acc: 0.9283 - val_loss: 0.2715 - val_acc: 0.8956\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.1027 - acc: 0.9638 - val_loss: 0.3137 - val_acc: 0.8933\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0488 - acc: 0.9846 - val_loss: 0.4029 - val_acc: 0.8933\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0259 - acc: 0.9917 - val_loss: 0.4798 - val_acc: 0.8937\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 15s 97us/step - loss: 0.0175 - acc: 0.9946 - val_loss: 0.5932 - val_acc: 0.8883\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0197 - acc: 0.9937 - val_loss: 0.6242 - val_acc: 0.8881\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0230 - acc: 0.9921 - val_loss: 0.6068 - val_acc: 0.8903\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.6930 - val_acc: 0.8903\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.6845 - val_acc: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc78f27e5c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = one_conv_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/one_conv_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('one_conv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/2\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.3367 - acc: 0.8506 - val_loss: 0.2630 - val_acc: 0.8931\n",
      "Epoch 2/2\n",
      "159586/159586 [==============================] - 19s 120us/step - loss: 0.1920 - acc: 0.9264 - val_loss: 0.2519 - val_acc: 0.9015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6e46d59b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = two_conv_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=2, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 24s 149us/step - loss: 0.3336 - acc: 0.8551 - val_loss: 0.2634 - val_acc: 0.8930\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.1917 - acc: 0.9261 - val_loss: 0.2782 - val_acc: 0.8935\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.1191 - acc: 0.9563 - val_loss: 0.2960 - val_acc: 0.8969\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0718 - acc: 0.9744 - val_loss: 0.3581 - val_acc: 0.8919\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0530 - acc: 0.9810 - val_loss: 0.4041 - val_acc: 0.8946\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0409 - acc: 0.9857 - val_loss: 0.4542 - val_acc: 0.8912\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0350 - acc: 0.9877 - val_loss: 0.4667 - val_acc: 0.8945\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0297 - acc: 0.9895 - val_loss: 0.4762 - val_acc: 0.8941\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0272 - acc: 0.9908 - val_loss: 0.5215 - val_acc: 0.8923\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 23s 144us/step - loss: 0.0251 - acc: 0.9914 - val_loss: 0.5166 - val_acc: 0.8946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7a1c706a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = two_conv_regularized_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_regularized_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 26s 163us/step - loss: 0.3402 - acc: 0.8516 - val_loss: 0.2778 - val_acc: 0.8862\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.1866 - acc: 0.9288 - val_loss: 0.2626 - val_acc: 0.8977\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.1074 - acc: 0.9611 - val_loss: 0.3988 - val_acc: 0.8715\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0670 - acc: 0.9763 - val_loss: 0.3544 - val_acc: 0.8928\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0445 - acc: 0.9844 - val_loss: 0.4103 - val_acc: 0.8950\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0391 - acc: 0.9862 - val_loss: 0.5156 - val_acc: 0.8810\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0355 - acc: 0.9875 - val_loss: 0.4411 - val_acc: 0.8973\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0298 - acc: 0.9898 - val_loss: 0.5007 - val_acc: 0.8920\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0223 - acc: 0.9925 - val_loss: 0.5215 - val_acc: 0.8930\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0220 - acc: 0.9925 - val_loss: 0.5183 - val_acc: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc72857b128>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = two_conv_regularized_larger_kernel_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_regularized_larger_kernel_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 200)          9242000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 99, 50)            20050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 99, 50)            200       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 98, 30)            3030      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 98, 30)            120       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 97, 20)            1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 97, 20)            80        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,272,333\n",
      "Trainable params: 9,272,133\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 20s 127us/step - loss: 0.3554 - acc: 0.8416 - val_loss: 0.2928 - val_acc: 0.8782\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.2256 - acc: 0.9123 - val_loss: 0.2755 - val_acc: 0.8907\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.1558 - acc: 0.9421 - val_loss: 0.2980 - val_acc: 0.8900\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.1077 - acc: 0.9608 - val_loss: 0.3252 - val_acc: 0.8913\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0768 - acc: 0.9723 - val_loss: 0.3717 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 18s 113us/step - loss: 0.0568 - acc: 0.9799 - val_loss: 0.4082 - val_acc: 0.8909\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0480 - acc: 0.9832 - val_loss: 0.4320 - val_acc: 0.8914\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0377 - acc: 0.9863 - val_loss: 0.4719 - val_acc: 0.8880\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0338 - acc: 0.9880 - val_loss: 0.4743 - val_acc: 0.8912\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0285 - acc: 0.9898 - val_loss: 0.5188 - val_acc: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6f2d39780>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = three_conv_regularized_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_regularized_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_regularized_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 30s 191us/step - loss: 0.3396 - acc: 0.8512 - val_loss: 0.2705 - val_acc: 0.8878\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.2051 - acc: 0.9194 - val_loss: 0.3167 - val_acc: 0.8768\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.1383 - acc: 0.9481 - val_loss: 0.2936 - val_acc: 0.8944\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0907 - acc: 0.9672 - val_loss: 0.3279 - val_acc: 0.8938\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0676 - acc: 0.9753 - val_loss: 0.3533 - val_acc: 0.8914\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0490 - acc: 0.9824 - val_loss: 0.3998 - val_acc: 0.8898\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0440 - acc: 0.9842 - val_loss: 0.4402 - val_acc: 0.8927\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0353 - acc: 0.9875 - val_loss: 0.4665 - val_acc: 0.8927\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0327 - acc: 0.9884 - val_loss: 0.4676 - val_acc: 0.8934\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 29s 179us/step - loss: 0.0273 - acc: 0.9904 - val_loss: 0.5207 - val_acc: 0.8887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6f2c0d5c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = three_conv_more_filter_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_more_filter_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_more_filter_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 33s 205us/step - loss: 0.3465 - acc: 0.8471 - val_loss: 0.2675 - val_acc: 0.8890\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.2036 - acc: 0.9211 - val_loss: 0.2792 - val_acc: 0.8907\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.1263 - acc: 0.9532 - val_loss: 0.2903 - val_acc: 0.8964\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.0844 - acc: 0.9695 - val_loss: 0.3360 - val_acc: 0.8939\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.0591 - acc: 0.9786 - val_loss: 0.3667 - val_acc: 0.8957\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.0436 - acc: 0.9850 - val_loss: 0.4240 - val_acc: 0.8922\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.0379 - acc: 0.9866 - val_loss: 0.4411 - val_acc: 0.8938\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 32s 198us/step - loss: 0.0331 - acc: 0.9886 - val_loss: 0.4420 - val_acc: 0.8970\n",
      "Epoch 9/10\n",
      " 16128/159586 [==>...........................] - ETA: 26s - loss: 0.0180 - acc: 0.9936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ced64ccba087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/three_conv_larger_kernel_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = three_conv_larger_kernel_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_larger_kernel_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 17s 105us/step - loss: 0.3486 - acc: 0.8453 - val_loss: 0.2852 - val_acc: 0.8809\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.1279 - acc: 0.9533 - val_loss: 0.3617 - val_acc: 0.8733\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 16s 102us/step - loss: 0.0319 - acc: 0.9898 - val_loss: 0.5536 - val_acc: 0.8721\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.7078 - val_acc: 0.8749\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 16s 102us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.8330 - val_acc: 0.8701\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 16s 102us/step - loss: 0.0242 - acc: 0.9917 - val_loss: 0.7343 - val_acc: 0.8716\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.8095 - val_acc: 0.8710\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.9035 - val_acc: 0.8710\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 1.0112 - val_acc: 0.8680\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 16s 102us/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.8952 - val_acc: 0.8697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6e5b41f60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vanilla_nn(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/vanilla_nn_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vanilla_nn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('two_conv_regularized_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 200)          9242000   \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 99, 100)           40100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 99, 100)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 96, 100)           40100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 96, 100)           400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,349,113\n",
      "Trainable params: 9,348,713\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "preds = np.round(model.predict(X_test)).T\n",
    "preds = preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 49871 test reviews, 4902 were misclassified.\n",
      "A few examples of the misclassified reviews:\n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 4\n",
      "this is good flavorful coffee but just not quite the right blend for me there are others i like more so will not be ordering it again good price from amazon though\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 5\n",
      "both my puppy puggle and 2 year old shitzu these treats it did in fact assist me in training the puggle but now that she is getting older and doing well i am starting to use this as a treat delivery was also fast so i was happy about that because it came at a perfect time\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "it gives your water a mild flavor the small packaging is very good handy to carry with you or keep in your desk this was fun to try but i prefer my water straight\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "the instructions on how to prepare this box of macaroni and cheese are basically the same as the regular kraft mac and cheese so it's very easy and of course it's great that vegetables are included in the pasta making it a bit more healthy than the regular the texture of the noodles was slightly mushier so i'd recommend undercooking them a bit if you want them to be more like the regular noodles i also thought the sauce seemed more bland not sure why that was since i only rarely each box macaroni and cheese and since i did\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 5\n",
      "this baby food processor is the best baby item i own it is really important to me to make my own baby food but the thought of chopping boiling steaming processing the veggies fruits and then washing all these items is just another annoying item to add to the list of to do's during the day the baby brezza makes all that so simple and easy that i don't mind taking this extra step to give my baby the best nutrients and save money all you need to do is chop the food stick it in the machine and wait\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "grew up in new england had lots of maple sugar candy that being said not very sweet and with a subtle maple flavor\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 4\n",
      "higgins burke's earl gray tea is mild but soothing i've noticed that this company produces very subtle mild tasting teas and i've sampled their green tea which also has a light clean taste this earl gray is a little bland certainly not as strong as the mighty leaf or tazo and it's easy to assume that the tea must not be very strong was i wrong i drank two cups just before bedtime and stayed awake almost all night i usually have a cup of lipton black tea before bed and the caffeine content in it must be very low\n",
      " \n"
     ]
    }
   ],
   "source": [
    "misclassifications = np.where(preds!=Y_test)\n",
    "misclassifications = misclassifications[0]\n",
    "print('Out of {} test reviews, {} were misclassified.'.format(len(Y_test), len(misclassifications)))\n",
    "print('A few examples of the misclassified reviews:')\n",
    "\n",
    "def print_sentence(index):\n",
    "    sentence_ix = misclassifications[index]\n",
    "    tmp = []\n",
    "    for val in X_test[sentence_ix]:\n",
    "        if ix_to_word[str(val)] == 'ZERO':\n",
    "            break\n",
    "        tmp.append(ix_to_word[str(val)])\n",
    "    processed_sentence = ' '.join(tmp)\n",
    "    print(processed_sentence)\n",
    "    \n",
    "def print_misclassification(index):\n",
    "    print('1. Predicted output: {} Actual label: {} Score: {}'.format(preds[misclassifications[index]], Y_test[misclassifications[index]], scores_test[misclassifications[index]]))\n",
    "    print_sentence(index)\n",
    "    print(' ')\n",
    "  \n",
    "print_misclassification(0)\n",
    "print_misclassification(10)\n",
    "print_misclassification(20)\n",
    "print_misclassification(30)\n",
    "print_misclassification(40)\n",
    "print_misclassification(50)\n",
    "print_misclassification(60)\n",
    "#print('1. Predicted output: {} Actual label: {} Score: {}'.format(preds[misclassifications[0]], Y_test[misclassifications[0]], scores_test[misclassifications[0]]))\n",
    "#print_sentence(0)\n",
    "#print('2. Predicted output: {} Actual label: {} Score: {}'.format(preds[misclassifications[1]], Y_test[misclassifications[1]], scores_test[misclassifications[1]]))\n",
    "#print_sentence(1)\n",
    "#print('3. Predicted output: {} Actual label: {} Score: {}'.format(preds[misclassifications[2]], Y_test[misclassifications[2]], scores_test[misclassifications[2]]))\n",
    "#print_sentence(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c865588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c97fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133c25a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### SCORE DISTRIBUTION ######\n",
    "plt.hist(scores_test, bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Total score distribution of test set')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Total number of data points: %d' %len(Y_even))\n",
    "\n",
    "plt.hist(scores_test[misclassifications], bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Score distribution of misclassifications')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "#plt.Axes.set_xticks(ticks=[1.5,2.5,3.5,4.5,5.5])\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Number of training data points: %d' %len(Y_train_even))\n",
    "\n",
    "num_scores = [sum(scores_test == 1), sum(scores_test == 2), sum(scores_test == 3), sum(scores_test == 4), sum(scores_test == 5)]\n",
    "num_scores_misclassifications = [sum(scores_test[misclassifications] == 1), sum(scores_test[misclassifications] == 2), sum(scores_test[misclassifications] == 3), sum(scores_test[misclassifications] == 4), sum(scores_test[misclassifications] == 5)]\n",
    "\n",
    "scaled_scores_mis = [num_scores_misclassifications[i]/num_scores[i] for i in range(5)]\n",
    "scaled_scores_mis = np.round([x*1000 for x in scaled_scores_mis])\n",
    "scaled_scores_mis_data = [1] * int(scaled_scores_mis[0]) + [2] * int(scaled_scores_mis[1]) + [3] * int(scaled_scores_mis[2]) + [4] * int(scaled_scores_mis[3]) + [5] * int(scaled_scores_mis[4])\n",
    "\n",
    "plt.hist(scaled_scores_mis_data, bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Score distribution of misclassifications')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "#plt.Axes.set_xticks(ticks=[1.5,2.5,3.5,4.5,5.5])\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Number of training data points: %d' %len(Y_train_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
