{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, First model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/lisasjoblom/anaconda3/envs/dml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 199483 training samples, 49871 test samples\n",
      "The length of each review is 100.\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "with open('X_train_even.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "    \n",
    "with open('Y_train_even.pickle', 'rb') as handle:\n",
    "    Y_train = pickle.load(handle)\n",
    "    \n",
    "with open('scores_train_even.pickle', 'rb') as handle:\n",
    "    scores_train = pickle.load(handle)\n",
    "    \n",
    "with open('X_test_even.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "    \n",
    "with open('Y_test_even.pickle', 'rb') as handle:\n",
    "    Y_test = pickle.load(handle)\n",
    "    \n",
    "with open('scores_test_even.pickle', 'rb') as handle:\n",
    "    scores_test = pickle.load(handle)\n",
    "    \n",
    "# import dictionaries\n",
    "with open('ix_to_word.pickle', 'rb') as handle:\n",
    "    ix_to_word = pickle.load(handle)\n",
    "    \n",
    "# small change in format\n",
    "tmp = np.concatenate(X_train).ravel()\n",
    "X_train = np.reshape(tmp,(len(X_train),100))\n",
    "\n",
    "tmp = np.concatenate(X_test).ravel()\n",
    "X_test = np.reshape(tmp,(len(X_test),100))\n",
    "\n",
    "review_length = X_test.shape[1]\n",
    "num_words = 46210\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print('The length of each review is {}.'.format(review_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 10000\n",
    "\n",
    "small_Y = Y_train[0:num_datapoints]\n",
    "small_X = X_train[0:num_datapoints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_conv_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_regularized_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_conv_regularized_larger_kernel_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_regularized_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=30, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=20, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_more_filter_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_conv_larger_kernel_model(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=100, kernel_size=5, padding='valid', activation='relu', strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_nn(review_length, num_words):\n",
    "    model = Sequential()\n",
    "    emb = Embedding(num_words, 200, input_length=review_length)\n",
    "    model.add(emb)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 16s 102us/step - loss: 0.3336 - acc: 0.8545 - val_loss: 0.2648 - val_acc: 0.8923\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 16s 99us/step - loss: 0.1908 - acc: 0.9278 - val_loss: 0.2627 - val_acc: 0.8970\n",
      "Epoch 3/10\n",
      " 19456/159586 [==>...........................] - ETA: 13s - loss: 0.0948 - acc: 0.9679"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-69119730f982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/one_conv_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = one_conv_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/one_conv_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('one_conv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 20s 125us/step - loss: 0.3355 - acc: 0.8510 - val_loss: 0.2604 - val_acc: 0.8952\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 19s 122us/step - loss: 0.1941 - acc: 0.9262 - val_loss: 0.2466 - val_acc: 0.9046\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 19s 122us/step - loss: 0.1109 - acc: 0.9608 - val_loss: 0.2889 - val_acc: 0.9001\n",
      "Epoch 4/10\n",
      " 35584/159586 [=====>........................] - ETA: 14s - loss: 0.0481 - acc: 0.9858"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-047250658c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/two_conv_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = two_conv_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 24s 150us/step - loss: 0.3301 - acc: 0.8572 - val_loss: 0.2646 - val_acc: 0.8923\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.1928 - acc: 0.9253 - val_loss: 0.2766 - val_acc: 0.8931\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.1160 - acc: 0.9573 - val_loss: 0.2986 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0727 - acc: 0.9737 - val_loss: 0.3534 - val_acc: 0.8931\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0531 - acc: 0.9811 - val_loss: 0.3977 - val_acc: 0.8948\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0408 - acc: 0.9852 - val_loss: 0.4566 - val_acc: 0.8923\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0361 - acc: 0.9871 - val_loss: 0.4469 - val_acc: 0.8929\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0289 - acc: 0.9898 - val_loss: 0.4775 - val_acc: 0.8956\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0248 - acc: 0.9916 - val_loss: 0.5276 - val_acc: 0.8925\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 23s 145us/step - loss: 0.0256 - acc: 0.9911 - val_loss: 0.5134 - val_acc: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f526c4b0518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = two_conv_regularized_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_regularized_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 26s 164us/step - loss: 0.3352 - acc: 0.8547 - val_loss: 0.2580 - val_acc: 0.8946\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.1795 - acc: 0.9315 - val_loss: 0.2779 - val_acc: 0.8946\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.1026 - acc: 0.9632 - val_loss: 0.3073 - val_acc: 0.8976\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0657 - acc: 0.9765 - val_loss: 0.3531 - val_acc: 0.8937\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0474 - acc: 0.9833 - val_loss: 0.4093 - val_acc: 0.8912\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0382 - acc: 0.9870 - val_loss: 0.4438 - val_acc: 0.8933\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0331 - acc: 0.9881 - val_loss: 0.4554 - val_acc: 0.8956\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0289 - acc: 0.9902 - val_loss: 0.4790 - val_acc: 0.8949\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0244 - acc: 0.9917 - val_loss: 0.5038 - val_acc: 0.8968\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 25s 154us/step - loss: 0.0241 - acc: 0.9916 - val_loss: 0.4957 - val_acc: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5204723fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = two_conv_regularized_larger_kernel_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/two_conv_regularized_larger_kernel_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 20s 128us/step - loss: 0.3580 - acc: 0.8400 - val_loss: 0.3134 - val_acc: 0.8712\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.2268 - acc: 0.9102 - val_loss: 0.2810 - val_acc: 0.8877\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.1562 - acc: 0.9408 - val_loss: 0.2874 - val_acc: 0.8926\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.1082 - acc: 0.9603 - val_loss: 0.3284 - val_acc: 0.8877\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 18s 113us/step - loss: 0.0764 - acc: 0.9725 - val_loss: 0.3547 - val_acc: 0.8910\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 18s 113us/step - loss: 0.0577 - acc: 0.9792 - val_loss: 0.4014 - val_acc: 0.8887\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0440 - acc: 0.9843 - val_loss: 0.4444 - val_acc: 0.8912\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0379 - acc: 0.9867 - val_loss: 0.4727 - val_acc: 0.8880\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0350 - acc: 0.9878 - val_loss: 0.4767 - val_acc: 0.8913\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 18s 112us/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.5229 - val_acc: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f522400f390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = three_conv_regularized_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_regularized_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_regularized_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 31s 191us/step - loss: 0.3437 - acc: 0.8488 - val_loss: 0.2888 - val_acc: 0.8819\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.2068 - acc: 0.9193 - val_loss: 0.2946 - val_acc: 0.8828\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.1354 - acc: 0.9497 - val_loss: 0.2924 - val_acc: 0.8954\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0942 - acc: 0.9650 - val_loss: 0.3692 - val_acc: 0.8846\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0648 - acc: 0.9762 - val_loss: 0.3815 - val_acc: 0.8911\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0501 - acc: 0.9824 - val_loss: 0.4029 - val_acc: 0.8960\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0418 - acc: 0.9850 - val_loss: 0.4637 - val_acc: 0.8909\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0354 - acc: 0.9875 - val_loss: 0.4339 - val_acc: 0.8948\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0313 - acc: 0.9889 - val_loss: 0.4573 - val_acc: 0.8938\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 29s 180us/step - loss: 0.0283 - acc: 0.9898 - val_loss: 0.4984 - val_acc: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51fc302ac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = three_conv_more_filter_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_more_filter_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_more_filter_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 33s 206us/step - loss: 0.3469 - acc: 0.8486 - val_loss: 0.2651 - val_acc: 0.8918\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 32s 199us/step - loss: 0.2004 - acc: 0.9233 - val_loss: 0.2572 - val_acc: 0.9007\n",
      "Epoch 3/10\n",
      "  9472/159586 [>.............................] - ETA: 28s - loss: 0.1057 - acc: 0.9639"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ced64ccba087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/three_conv_larger_kernel_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = three_conv_larger_kernel_model(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/three_conv_larger_kernel_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('three_conv_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159586 samples, validate on 39897 samples\n",
      "Epoch 1/10\n",
      "159586/159586 [==============================] - 17s 106us/step - loss: 0.3506 - acc: 0.8432 - val_loss: 0.2846 - val_acc: 0.8824\n",
      "Epoch 2/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.1253 - acc: 0.9538 - val_loss: 0.3607 - val_acc: 0.8746\n",
      "Epoch 3/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 0.5388 - val_acc: 0.8730\n",
      "Epoch 4/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.7066 - val_acc: 0.8738\n",
      "Epoch 5/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0109 - acc: 0.9961 - val_loss: 0.8276 - val_acc: 0.8681\n",
      "Epoch 6/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.7670 - val_acc: 0.8720\n",
      "Epoch 7/10\n",
      "159586/159586 [==============================] - 17s 104us/step - loss: 0.0093 - acc: 0.9966 - val_loss: 0.8581 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "159586/159586 [==============================] - 17s 104us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.9432 - val_acc: 0.8733\n",
      "Epoch 9/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.9510 - val_acc: 0.8671\n",
      "Epoch 10/10\n",
      "159586/159586 [==============================] - 16s 103us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.9545 - val_acc: 0.8697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51c294dfd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vanilla_nn(review_length, num_words)\n",
    "tb = TensorBoard(log_dir='./logs/vanilla_nn_model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])\n",
    "#model.fit(small_X, small_Y, validation_split=0.2, epochs=10, batch_size=256, verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vanilla_nn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('two_conv_regularized_larger_kernel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('two_conv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 100, 200)          9242000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 99, 100)           40100     \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 98, 100)           20100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,328,313\n",
      "Trainable params: 9,328,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "preds = np.round(model.predict(X_test)).T\n",
    "preds = preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 49871 test reviews, 4909 were misclassified.\n",
      "A few examples of the misclassified reviews:\n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 4\n",
      "i am ordering the coconut raw nectar again becasue of the health benifits and i like it in my coffee the last package was packaged very well but the last bottle has begun to crystalize which means its not as fresh i have purchased this product before in bulk in my community and never had a problem with it crystalizing i hope this next shipment will be fresh\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 4\n",
      "i would hope it would go without saying but if you don't like plain almonds you probably won't like them sprinkled with cocoa powder i like almonds particularly for their health benefits that are fairly well known i usually avoid them covered in salt and flavoring powder but i'm glad i gave these a try the packaging suggests dark chocolate and it would be easy to get the wrong idea that these will taste chocolate in the sense of milk chocolate perhaps i just expected them to taste like almonds and cocoa which they do so they are semi sweet\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 4\n",
      "used chicken rather than beef saving of around 3g of fat per serving it was tasty but i do think that the beef would have enhanced the meal more very easy to prepare cooked the dish on high for 5 hours left it to warm for 30 mins and then cooked it on low again for 30 mins beans were just about done they were still a little bit crunchy which be to everyone's taste i'd make this again\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "i love mio the berry pomegranate is my favorite for years i only drank soda and that's not healthy so i wanted something with flavor to satify my taste but not expand my waist i recieved this as a sample from facebook about a year ago and it is all i drink it cost less than 4 00 a bottle at target where i am at so amazon charging about 6 00 is a rip so try to find it elsewhere first if anything email mio and find out where they have it avalable in your area i also love\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "i regularly drink herbal iced teas at home but i also bring powdered flavor packets and bottled water to drink at work i much prefer the flavor of real iced tea but flavored water can be a good convenient and cost effective drink while away from home the mio flavoring is a good concept for flavoring water easily since you don't have to deal with messy powders which often seem to spill and go everywhere but it has some flaws that keep it from being a great product i have tried two different flavors of mio and those were the\n",
      " \n",
      "1. Predicted output: 0.0 Actual label: 1 Score: 5\n",
      "very smooth and rich flavor i do not compare it to coffee although it is my coffee alternative these days you need about 25% of what an average brewed pot of coffee calls for with this grind or it is unpleasantly strong\n",
      " \n",
      "1. Predicted output: 1.0 Actual label: 0 Score: 3\n",
      "grew up in new england had lots of maple sugar candy that being said not very sweet and with a subtle maple flavor\n",
      " \n"
     ]
    }
   ],
   "source": [
    "misclassifications = np.where(preds!=Y_test)\n",
    "misclassifications = misclassifications[0]\n",
    "print('Out of {} test reviews, {} were misclassified.'.format(len(Y_test), len(misclassifications)))\n",
    "print('A few examples of the misclassified reviews:')\n",
    "\n",
    "def print_sentence(index):\n",
    "    sentence_ix = misclassifications[index]\n",
    "    tmp = []\n",
    "    for val in X_test[sentence_ix]:\n",
    "        if ix_to_word[str(val)] == 'ZERO':\n",
    "            break\n",
    "        tmp.append(ix_to_word[str(val)])\n",
    "    processed_sentence = ' '.join(tmp)\n",
    "    print(processed_sentence)\n",
    "    \n",
    "def print_misclassification(index):\n",
    "    print('1. Predicted output: {} Actual label: {} Score: {}'.format(preds[misclassifications[index]], Y_test[misclassifications[index]], scores_test[misclassifications[index]]))\n",
    "    print_sentence(index)\n",
    "    print(' ')\n",
    "  \n",
    "print_misclassification(0)\n",
    "print_misclassification(10)\n",
    "print_misclassification(20)\n",
    "print_misclassification(30)\n",
    "print_misclassification(40)\n",
    "print_misclassification(50)\n",
    "print_misclassification(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisasjoblom/anaconda3/envs/dml/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### SCORE DISTRIBUTION ######\n",
    "plt.hist(scores_test, bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Total score distribution of test set')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Total number of data points: %d' %len(Y_even))\n",
    "\n",
    "plt.hist(scores_test[misclassifications], bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Score distribution of misclassifications')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "#plt.Axes.set_xticks(ticks=[1.5,2.5,3.5,4.5,5.5])\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Number of training data points: %d' %len(Y_train_even))\n",
    "\n",
    "num_scores = [sum(scores_test == 1), sum(scores_test == 2), sum(scores_test == 3), sum(scores_test == 4), sum(scores_test == 5)]\n",
    "num_scores_misclassifications = [sum(scores_test[misclassifications] == 1), sum(scores_test[misclassifications] == 2), sum(scores_test[misclassifications] == 3), sum(scores_test[misclassifications] == 4), sum(scores_test[misclassifications] == 5)]\n",
    "\n",
    "scaled_scores_mis = [num_scores_misclassifications[i]/num_scores[i] for i in range(5)]\n",
    "scaled_scores_mis = np.round([x*1000 for x in scaled_scores_mis])\n",
    "scaled_scores_mis_data = [1] * int(scaled_scores_mis[0]) + [2] * int(scaled_scores_mis[1]) + [3] * int(scaled_scores_mis[2]) + [4] * int(scaled_scores_mis[3]) + [5] * int(scaled_scores_mis[4])\n",
    "\n",
    "plt.hist(scaled_scores_mis_data, bins=[1,2,3,4,5,6], normed=True)\n",
    "plt.title('Score distribution of misclassifications')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Score')\n",
    "#plt.Axes.set_xticks(ticks=[1.5,2.5,3.5,4.5,5.5])\n",
    "plt.xticks([1.5,2.5,3.5,4.5,5.5],[1,2,3,4,5])\n",
    "plt.show()\n",
    "#print('Number of training data points: %d' %len(Y_train_even))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
