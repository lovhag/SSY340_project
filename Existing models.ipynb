{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "#nltk.download('perluniprops')\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch even data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of even training data points: 199483\n"
     ]
    }
   ],
   "source": [
    "with open('X_train_even.pickle', 'rb') as handle:\n",
    "    X_train_even = pickle.load(handle)\n",
    "    \n",
    "# with open('X_test_even.pickle', 'rb') as handle:\n",
    "#     X_test_even = pickle.load(handle)\n",
    "    \n",
    "with open('Y_train_even.pickle', 'rb') as handle:\n",
    "    Y_train_even = pickle.load(handle)\n",
    "    \n",
    "# with open('Y_test_even.pickle', 'rb') as handle:\n",
    "#     Y_test_even = pickle.load(handle)\n",
    "\n",
    "print('Total number of even training data points: %d' %len(X_train_even))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing model on even data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a smaller data set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of negative reviews:\n",
      "0.4924\n",
      "It is approximately even!\n"
     ]
    }
   ],
   "source": [
    "lesser_number = 10000\n",
    "\n",
    "small_Y = Y_train_even[0:lesser_number]\n",
    "small_X = X_train_even[0:lesser_number]\n",
    "neg_share = len(small_Y[small_Y==1])/lesser_number\n",
    "\n",
    "print('The share of negative reviews:')\n",
    "print(neg_share)\n",
    "print('It is approximately even!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ix_to_word.pickle', 'rb') as handle:\n",
    "    ix_to_word = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X_text = []\n",
    "for row in small_X:\n",
    "    small_X_text_vec = []\n",
    "    for value in row:\n",
    "        tmp = ix_to_word[str(value[0])]\n",
    "        if tmp != 'ZERO':\n",
    "            small_X_text_vec.append(tmp)\n",
    "    small_X_text.append(' '.join(small_X_text_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = []\n",
    "for row in X_train_even:\n",
    "    X_text_vec = []\n",
    "    for value in row:\n",
    "        tmp = ix_to_word[str(value[0])]\n",
    "        if tmp != 'ZERO':\n",
    "            X_text_vec.append(tmp)\n",
    "    X_text.append(' '.join(X_text_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tge first bag i had was good and a nice change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i first got them he gulped them down but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i've bought these at the local supermarket and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this extract doesn't smell like roses at all i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my 11 month old has been eating these since sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              X_text\n",
       "0  tge first bag i had was good and a nice change...\n",
       "1  when i first got them he gulped them down but ...\n",
       "2  i've bought these at the local supermarket and...\n",
       "3  this extract doesn't smell like roses at all i...\n",
       "4  my 11 month old has been eating these since sh..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_X = pd.DataFrame(data={'small_X_text': small_X_text})   \n",
    "#print(str(small_X_text[0]))\n",
    "df_X = pd.DataFrame(data={'X_text': X_text})\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 37967\n",
      "# train records: 149612\n",
      "# test records: 49871\n",
      "Model validation accuracy: 0.8515570171041287\n",
      "\n",
      "-Top 20 positive-\n",
      "Word  Coefficient\n",
      "    hahaha     2.624796\n",
      "    tilted     2.564642\n",
      "  outright     2.343050\n",
      " impatient     2.332832\n",
      " skeptical     2.280466\n",
      "   blowout     2.271859\n",
      "     youve     2.247146\n",
      "  perruche     2.244868\n",
      "   tribute     2.224237\n",
      "   holster     2.220300\n",
      "      team     2.191185\n",
      "    hooked     2.156622\n",
      "       eko     2.107698\n",
      "pleasantly     2.085768\n",
      "       h20     2.052638\n",
      "    ticket     2.025280\n",
      " shellfish     2.021449\n",
      "    eludes     2.007253\n",
      "     hears     1.984752\n",
      "     scare     1.957880\n",
      "\n",
      "-Top 20 negative-\n",
      "Word  Coefficient\n",
      "   oversalted    -2.189888\n",
      "      whitish    -2.190605\n",
      "        alley    -2.203429\n",
      "     feingold    -2.213227\n",
      "  unimpressed    -2.218808\n",
      "        eject    -2.251041\n",
      " underwhelmed    -2.258160\n",
      "        schar    -2.283353\n",
      "    foolproof    -2.312021\n",
      "          ick    -2.331629\n",
      "disappointing    -2.397969\n",
      "     doughnut    -2.423711\n",
      "        worst    -2.459400\n",
      "    deceptive    -2.479038\n",
      "    perimeter    -2.510478\n",
      "      bounced    -2.929111\n",
      "    amendment    -3.009095\n",
      "    quickness    -3.045985\n",
      "   unfinished    -3.074327\n",
      "        aways    -3.124255\n"
     ]
    }
   ],
   "source": [
    "c = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "def text_fit(X, y, model, clf_model, coef_show=1):\n",
    "    \n",
    "    # Extract features for the data using 'model'\n",
    "    X_c = model.fit_transform(X)\n",
    "    print('# features: {}'.format(X_c.shape[1]))\n",
    "    # Validation data split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0)\n",
    "    print('# train records: {}'.format(X_train.shape[0]))\n",
    "    print('# test records: {}'.format(X_test.shape[0]))\n",
    "    \n",
    "    # Fit on the features with 'clf_model'\n",
    "    clf = clf_model.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print ('Model validation accuracy: {}'.format(acc))\n",
    "\n",
    "    if coef_show == 1: \n",
    "        w = model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('-Top 20 positive-')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('-Top 20 negative-')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "     \n",
    "X_for_fit = df_X['X_text']\n",
    "text_fit(X_for_fit, Y_train_even, c, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 37967\n",
      "# train records: 149612\n",
      "# test records: 49871\n",
      "Model validation accuracy: 0.848669567484109\n",
      "\n",
      "-Top 20 positive-\n",
      "Word  Coefficient\n",
      "     great     8.928481\n",
      "      best     8.630061\n",
      " delicious     8.506898\n",
      "   perfect     8.328324\n",
      " excellent     7.250155\n",
      "     loves     7.135029\n",
      "    highly     6.803392\n",
      " wonderful     6.534695\n",
      "      love     6.330726\n",
      "    hooked     6.226441\n",
      "   amazing     6.186373\n",
      "   awesome     5.823596\n",
      "      glad     5.790674\n",
      "   pleased     5.666403\n",
      "pleasantly     5.512839\n",
      " skeptical     5.392021\n",
      "     yummy     5.326724\n",
      "  favorite     5.151990\n",
      "     thank     4.971193\n",
      "    smooth     4.826595\n",
      "\n",
      "-Top 20 negative-\n",
      "Word  Coefficient\n",
      "           bad    -4.626346\n",
      "         maybe    -4.783946\n",
      "         worse    -4.939055\n",
      "        return    -5.143786\n",
      "         stale    -5.254722\n",
      "         bland    -5.309755\n",
      "    disgusting    -5.504398\n",
      "       thought    -5.519244\n",
      "          weak    -5.520669\n",
      "        hoping    -5.706549\n",
      "disappointment    -6.003089\n",
      "      terrible    -6.446847\n",
      "          okay    -6.480196\n",
      "         awful    -6.729751\n",
      "            ok    -7.077576\n",
      "      horrible    -7.335758\n",
      "  disappointed    -7.563279\n",
      " disappointing    -7.824624\n",
      " unfortunately    -7.848689\n",
      "         worst    -9.028982\n"
     ]
    }
   ],
   "source": [
    "# Like CountVectorizer but it also applies \n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "text_fit(X_for_fit, Y_train_even, tfidf, LogisticRegression())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
